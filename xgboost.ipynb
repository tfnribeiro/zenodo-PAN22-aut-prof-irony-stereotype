{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yananikolova/opt/anaconda3/lib/python3.9/site-packages/xgboost/compat.py:36: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  from pandas import MultiIndex, Int64Index\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load XML files complete, number of tweet profiles:  420\n"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "from read_files import X,y\n",
    "from sklearn.model_selection import train_test_split\n",
    "from classifier_methods import *\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating Train Features\n",
      "Generating Train Features\n",
      "Processing features: pos_counts\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 315/315 [00:55<00:00,  5.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Individual Predict Processing for features: pos_counts, is complete!\n",
      "Processing features: author_style_counts\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 315/315 [00:15<00:00, 20.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Individual Predict Processing for features: author_style_counts, is complete!\n",
      "Processing features: lix_score\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 315/315 [00:07<00:00, 43.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Individual Predict Processing for features: lix_score, is complete!\n",
      "Processing features: get_sent_polarity\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 315/315 [00:17<00:00, 18.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Individual Predict Processing for features: get_sent_polarity, is complete!\n",
      "Processing features: seperated_punctuation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 315/315 [00:00<00:00, 422.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Individual Predict Processing for features: seperated_punctuation, is complete!\n",
      "Generating Train Features\n",
      "Generating IDF Vector\n",
      "Processing features: tf_idf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 315/315 [00:06<00:00, 45.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Emoji TF_IDF Processing for features: tf_idf, is complete!\n",
      "Generating IDF Vector\n",
      "Processing features: tf_idf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 315/315 [00:07<00:00, 43.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Profanity TF_IDF Processing for features: tf_idf, is complete!\n",
      "Generating IDF Vector\n",
      "Processing features: tf_idf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 315/315 [00:17<00:00, 18.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Words TF_IDF Processing for features: tf_idf, is complete!\n",
      "Emoji Explained Variance:  0.42238571769701533\n",
      "Profanity Explained Variance:  0.5723355082808844\n",
      "Word Explained Variance:  0.4686291396061584\n"
     ]
    }
   ],
   "source": [
    "X_train_features, *settings = get_features_train(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating Test Features\n",
      "Processing features: pos_counts\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 105/105 [00:19<00:00,  5.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Individual Predict Processing for features: pos_counts, is complete!\n",
      "Processing features: author_style_counts\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 105/105 [00:05<00:00, 19.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Individual Predict Processing for features: author_style_counts, is complete!\n",
      "Processing features: lix_score\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 105/105 [00:02<00:00, 42.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Individual Predict Processing for features: lix_score, is complete!\n",
      "Processing features: get_sent_polarity\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 105/105 [00:05<00:00, 18.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Individual Predict Processing for features: get_sent_polarity, is complete!\n",
      "Processing features: seperated_punctuation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 105/105 [00:00<00:00, 426.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Individual Predict Processing for features: seperated_punctuation, is complete!\n",
      "Processing features: tf_idf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 105/105 [00:02<00:00, 44.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Individual Predict Processing for features: tf_idf, is complete!\n",
      "Processing features: tf_idf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 105/105 [00:02<00:00, 43.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Individual Predict Processing for features: tf_idf, is complete!\n",
      "Processing features: tf_idf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 105/105 [00:05<00:00, 18.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Words TF_IDF Processing for features: tf_idf, is complete!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "X_test_features = get_features_test(X_test, *settings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train[y_train == 'I'] = 1\n",
    "y_train[y_train == 'NI'] = 0\n",
    "\n",
    "y_test[y_test == 'I'] = 1\n",
    "y_test[y_test == 'NI'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtrain = xgb.DMatrix(X_train_features, label=y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "param = {'max_depth': 4, 'eta': 1, 'objective': 'binary:hinge', 'eval_metric':'error'}\n",
    "num_round = 10\n",
    "bst = xgb.train(param, dtrain, num_round)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dtest = xgb.DMatrix(X_test_features)\n",
    "ypred = bst.predict(dtest)\n",
    "np.sum(y_test.astype(int) == ypred)/105\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=1, enable_categorical=False,\n",
       "              eval_metric='error', gamma=0, gpu_id=-1, importance_type=None,\n",
       "              interaction_constraints='', learning_rate=0.300000012,\n",
       "              max_delta_step=0, max_depth=6, min_child_weight=1, missing=nan,\n",
       "              monotone_constraints='()', n_estimators=100, n_jobs=8,\n",
       "              num_parallel_tree=1, predictor='auto', random_state=0,\n",
       "              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, subsample=1,\n",
       "              tree_method='hist', use_label_encoder=False,\n",
       "              validate_parameters=1, verbosity=None)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg = xgb.XGBClassifier(tree_method=\"hist\", eval_metric = 'error', use_label_encoder=False)\n",
    "# Fit the model using predictor X and response y.\n",
    "reg.fit(X_train_features, y_train.astype(int))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Performance\n",
      "Average Error: 0.0857 degrees.\n",
      "Accuracy = 0.91%.\n",
      "Fitting 4 folds for each of 540 candidates, totalling 2160 fits\n",
      "{'learning_rate': 0.1, 'max_depth': 3, 'min_child_weight': 7, 'n_estimators': 150, 'tree_method': 'hist'}\n",
      "Model Performance\n",
      "Average Error: 0.0952 degrees.\n",
      "Accuracy = 0.90%.\n",
      "Improvement of -1.04%.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "def evaluate(model, test_features, test_labels):\n",
    "    predictions = model.predict(test_features)\n",
    "    errors = abs(predictions != test_labels)\n",
    "    accuracy = (predictions==test_labels).sum()/len(test_labels)\n",
    "    print('Model Performance')\n",
    "    print('Average Error: {:0.4f} degrees.'.format(np.mean(errors)))\n",
    "    print('Accuracy = {:0.2f}%.'.format(accuracy))\n",
    "    return accuracy\n",
    "\n",
    "\n",
    "clf_rfc = xgb.XGBClassifier(eval_metric = 'error', use_label_encoder=False, random_state = 0)\n",
    "\n",
    "clf_rfc.fit(X_train_features, y_train.astype(int))\n",
    "base_accuracy = evaluate(clf_rfc, X_test_features, y_test.astype(int))\n",
    "\n",
    "clf_rfc = xgb.XGBClassifier(eval_metric = 'error', use_label_encoder = False, random_state = 0)\n",
    "\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 150, 200],\n",
    "    'tree_method': ['hist', 'auto', 'exact'],\n",
    "    'max_depth': [3,5, 7, 10, 15],\n",
    "    'min_child_weight': [1,3,5,7],\n",
    "    'learning_rate': [0.1, 0.2, 0.3]\n",
    "    \n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(estimator = clf_rfc, param_grid = param_grid, cv = 4, n_jobs = -1, verbose = 1)\n",
    "grid_search.fit(X_train_features, y_train.astype(int))\n",
    "print(grid_search.best_params_)\n",
    "\n",
    "best_grid = grid_search.best_estimator_\n",
    "grid_accuracy = evaluate(best_grid, X_test_features, y_test.astype(int))\n",
    "\n",
    "print('Improvement of {:0.2f}%.'.format( 100 * (grid_accuracy - base_accuracy) / base_accuracy))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "ae83aaff4c47202ead0cb5b0cfe74444d437ac818c9c2cd6826845dc75a11708"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
