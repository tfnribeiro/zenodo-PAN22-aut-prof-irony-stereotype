{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mCanceled future for execute_request message before replies were done"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn import svm\n",
    "from read_files import X,y\n",
    "from read_files import USERCODE_X\n",
    "from utils import tokenize_tweet\n",
    "import numpy as np\n",
    "import regex as re\n",
    "from io import StringIO\n",
    "from sklearn.model_selection import train_test_split\n",
    "from nltk.tokenize import TweetTokenizer \n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#collecting all text for all authors \n",
    "\n",
    "def collect(array):\n",
    "\n",
    "    train_author = [None for i in range(array.shape[0])]\n",
    "\n",
    "    for i, author in enumerate(array):\n",
    "        buf = StringIO()\n",
    "        for tweet in author:\n",
    "            buf.write(tweet + \"\")\n",
    "        single_text = buf.getvalue()\n",
    "        train_author[i] = single_text\n",
    "\n",
    "    train_author = np.array(train_author)\n",
    "    return train_author \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#counting bigrams \n",
    "\n",
    "tknzr = TweetTokenizer()\n",
    "vectorizer = CountVectorizer(analyzer='word', tokenizer = tknzr.tokenize, ngram_range=(2, 2))\n",
    "X_train_f = vectorizer.fit_transform(collect(X_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_f = vectorizer.transform(collect(X_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC()"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = svm.SVC()\n",
    "clf.fit(X_train_f, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8095238095238095"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#word accuracy\n",
    "accuracy_score(y_test, clf.predict(X_test_f))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer(analyzer='char', ngram_range=(2, 2))\n",
    "X_train_f = vectorizer.fit_transform(collect(X_train))\n",
    "X_test_f = vectorizer.transform(collect(X_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8380952380952381"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#char accuracy\n",
    "clf = svm.SVC()\n",
    "clf.fit(X_train_f, y_train)\n",
    "accuracy_score(y_test, clf.predict(X_test_f))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ERROR! Session/line number was not unique in"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: '#USER# Sounds like being down on the farm............with no swimming pools...'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[0;32mIn [138]\u001b[0m, in \u001b[0;36m<cell line: 6>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39msklearn\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mdecomposition\u001b[39;00m \u001b[39mimport\u001b[39;00m PCA\n\u001b[1;32m      5\u001b[0m pca \u001b[39m=\u001b[39m PCA(n_components\u001b[39m=\u001b[39m\u001b[39m10\u001b[39m)\n\u001b[0;32m----> 6\u001b[0m pca\u001b[39m.\u001b[39;49mfit(X_train)\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/sklearn/decomposition/_pca.py:382\u001b[0m, in \u001b[0;36mPCA.fit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    <a href='file:///Users/yananikolova/opt/anaconda3/lib/python3.9/site-packages/sklearn/decomposition/_pca.py?line=364'>365</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfit\u001b[39m(\u001b[39mself\u001b[39m, X, y\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[1;32m    <a href='file:///Users/yananikolova/opt/anaconda3/lib/python3.9/site-packages/sklearn/decomposition/_pca.py?line=365'>366</a>\u001b[0m     \u001b[39m\"\"\"Fit the model with X.\u001b[39;00m\n\u001b[1;32m    <a href='file:///Users/yananikolova/opt/anaconda3/lib/python3.9/site-packages/sklearn/decomposition/_pca.py?line=366'>367</a>\u001b[0m \n\u001b[1;32m    <a href='file:///Users/yananikolova/opt/anaconda3/lib/python3.9/site-packages/sklearn/decomposition/_pca.py?line=367'>368</a>\u001b[0m \u001b[39m    Parameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    <a href='file:///Users/yananikolova/opt/anaconda3/lib/python3.9/site-packages/sklearn/decomposition/_pca.py?line=379'>380</a>\u001b[0m \u001b[39m        Returns the instance itself.\u001b[39;00m\n\u001b[1;32m    <a href='file:///Users/yananikolova/opt/anaconda3/lib/python3.9/site-packages/sklearn/decomposition/_pca.py?line=380'>381</a>\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> <a href='file:///Users/yananikolova/opt/anaconda3/lib/python3.9/site-packages/sklearn/decomposition/_pca.py?line=381'>382</a>\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_fit(X)\n\u001b[1;32m    <a href='file:///Users/yananikolova/opt/anaconda3/lib/python3.9/site-packages/sklearn/decomposition/_pca.py?line=382'>383</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/sklearn/decomposition/_pca.py:430\u001b[0m, in \u001b[0;36mPCA._fit\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    <a href='file:///Users/yananikolova/opt/anaconda3/lib/python3.9/site-packages/sklearn/decomposition/_pca.py?line=423'>424</a>\u001b[0m \u001b[39mif\u001b[39;00m issparse(X):\n\u001b[1;32m    <a href='file:///Users/yananikolova/opt/anaconda3/lib/python3.9/site-packages/sklearn/decomposition/_pca.py?line=424'>425</a>\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\n\u001b[1;32m    <a href='file:///Users/yananikolova/opt/anaconda3/lib/python3.9/site-packages/sklearn/decomposition/_pca.py?line=425'>426</a>\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mPCA does not support sparse input. See \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    <a href='file:///Users/yananikolova/opt/anaconda3/lib/python3.9/site-packages/sklearn/decomposition/_pca.py?line=426'>427</a>\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mTruncatedSVD for a possible alternative.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    <a href='file:///Users/yananikolova/opt/anaconda3/lib/python3.9/site-packages/sklearn/decomposition/_pca.py?line=427'>428</a>\u001b[0m     )\n\u001b[0;32m--> <a href='file:///Users/yananikolova/opt/anaconda3/lib/python3.9/site-packages/sklearn/decomposition/_pca.py?line=429'>430</a>\u001b[0m X \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_validate_data(\n\u001b[1;32m    <a href='file:///Users/yananikolova/opt/anaconda3/lib/python3.9/site-packages/sklearn/decomposition/_pca.py?line=430'>431</a>\u001b[0m     X, dtype\u001b[39m=\u001b[39;49m[np\u001b[39m.\u001b[39;49mfloat64, np\u001b[39m.\u001b[39;49mfloat32], ensure_2d\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, copy\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcopy\n\u001b[1;32m    <a href='file:///Users/yananikolova/opt/anaconda3/lib/python3.9/site-packages/sklearn/decomposition/_pca.py?line=431'>432</a>\u001b[0m )\n\u001b[1;32m    <a href='file:///Users/yananikolova/opt/anaconda3/lib/python3.9/site-packages/sklearn/decomposition/_pca.py?line=433'>434</a>\u001b[0m \u001b[39m# Handle n_components==None\u001b[39;00m\n\u001b[1;32m    <a href='file:///Users/yananikolova/opt/anaconda3/lib/python3.9/site-packages/sklearn/decomposition/_pca.py?line=434'>435</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_components \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/sklearn/base.py:566\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[0;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[1;32m    <a href='file:///Users/yananikolova/opt/anaconda3/lib/python3.9/site-packages/sklearn/base.py?line=563'>564</a>\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mValidation should be done on X, y or both.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    <a href='file:///Users/yananikolova/opt/anaconda3/lib/python3.9/site-packages/sklearn/base.py?line=564'>565</a>\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mnot\u001b[39;00m no_val_X \u001b[39mand\u001b[39;00m no_val_y:\n\u001b[0;32m--> <a href='file:///Users/yananikolova/opt/anaconda3/lib/python3.9/site-packages/sklearn/base.py?line=565'>566</a>\u001b[0m     X \u001b[39m=\u001b[39m check_array(X, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mcheck_params)\n\u001b[1;32m    <a href='file:///Users/yananikolova/opt/anaconda3/lib/python3.9/site-packages/sklearn/base.py?line=566'>567</a>\u001b[0m     out \u001b[39m=\u001b[39m X\n\u001b[1;32m    <a href='file:///Users/yananikolova/opt/anaconda3/lib/python3.9/site-packages/sklearn/base.py?line=567'>568</a>\u001b[0m \u001b[39melif\u001b[39;00m no_val_X \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m no_val_y:\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py:746\u001b[0m, in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator)\u001b[0m\n\u001b[1;32m    <a href='file:///Users/yananikolova/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py?line=743'>744</a>\u001b[0m         array \u001b[39m=\u001b[39m array\u001b[39m.\u001b[39mastype(dtype, casting\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39munsafe\u001b[39m\u001b[39m\"\u001b[39m, copy\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n\u001b[1;32m    <a href='file:///Users/yananikolova/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py?line=744'>745</a>\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> <a href='file:///Users/yananikolova/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py?line=745'>746</a>\u001b[0m         array \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39;49masarray(array, order\u001b[39m=\u001b[39;49morder, dtype\u001b[39m=\u001b[39;49mdtype)\n\u001b[1;32m    <a href='file:///Users/yananikolova/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py?line=746'>747</a>\u001b[0m \u001b[39mexcept\u001b[39;00m ComplexWarning \u001b[39mas\u001b[39;00m complex_warning:\n\u001b[1;32m    <a href='file:///Users/yananikolova/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py?line=747'>748</a>\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    <a href='file:///Users/yananikolova/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py?line=748'>749</a>\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mComplex data not supported\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m{}\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(array)\n\u001b[1;32m    <a href='file:///Users/yananikolova/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py?line=749'>750</a>\u001b[0m     ) \u001b[39mfrom\u001b[39;00m \u001b[39mcomplex_warning\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/numpy/core/_asarray.py:102\u001b[0m, in \u001b[0;36masarray\u001b[0;34m(a, dtype, order, like)\u001b[0m\n\u001b[1;32m     <a href='file:///Users/yananikolova/opt/anaconda3/lib/python3.9/site-packages/numpy/core/_asarray.py?line=98'>99</a>\u001b[0m \u001b[39mif\u001b[39;00m like \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    <a href='file:///Users/yananikolova/opt/anaconda3/lib/python3.9/site-packages/numpy/core/_asarray.py?line=99'>100</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m _asarray_with_like(a, dtype\u001b[39m=\u001b[39mdtype, order\u001b[39m=\u001b[39morder, like\u001b[39m=\u001b[39mlike)\n\u001b[0;32m--> <a href='file:///Users/yananikolova/opt/anaconda3/lib/python3.9/site-packages/numpy/core/_asarray.py?line=101'>102</a>\u001b[0m \u001b[39mreturn\u001b[39;00m array(a, dtype, copy\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m, order\u001b[39m=\u001b[39;49morder)\n",
      "\u001b[0;31mValueError\u001b[0m: could not convert string to float: '#USER# Sounds like being down on the farm............with no swimming pools...'"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " database. History logging moved to new session 355\n"
     ]
    }
   ],
   "source": [
    "X_train_f.shape[0]\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "pca = PCA(n_components=10)\n",
    "pca.fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "buf = StringIO()\n",
    "\n",
    "for author in X:\n",
    "    for tweet in author:\n",
    "         buf.write(tweet + \"\")\n",
    "single_text = buf.getvalue()\n",
    "\n",
    "vectorizer = CountVectorizer(analyzer = 'char', ngram_range = (2,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_bigrams = vectorizer.fit_transform([single_text])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 13972)"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_bigrams.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "ae83aaff4c47202ead0cb5b0cfe74444d437ac818c9c2cd6826845dc75a11708"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
